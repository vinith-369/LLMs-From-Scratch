{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4a8fc3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/Users/vinithlankireddy/Projects/LLMs/GPT-2/f/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "raw_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6d94a447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20479"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "19058356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ', ', 'world', '. ', 'Is this-- a test?']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello, world. Is this-- a test?\"\n",
    "\n",
    "result = re.split(r'([,.:;?_!\"\\'] | -- | \\s)', text)\n",
    "# result = [item for item in result ]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e54cda9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'world', '.', 'Is this-- a test?']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [item.strip() for item in result if item.strip()]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "80177d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "# preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e78e14cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'HAD',\n",
       " 'always',\n",
       " 'thought',\n",
       " 'Jack',\n",
       " 'Gisburn',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'cheap',\n",
       " 'genius']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "preprocessed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cb5b02a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "713a95dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_len = len(all_words)\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5a1d9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token : i for i,token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5c4a3f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i>=10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "21e8c866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '!')\n",
      "(1, '\"')\n",
      "(2, \"'\")\n",
      "(3, '(')\n",
      "(4, ')')\n",
      "(5, ',')\n",
      "(6, '--')\n",
      "(7, '.')\n",
      "(8, ':')\n",
      "(9, ';')\n",
      "(10, '?')\n"
     ]
    }
   ],
   "source": [
    "int_to_str = {i:s for s,i in vocab.items()}\n",
    "for i,item in enumerate(int_to_str.items()):\n",
    "    print(item)\n",
    "    if i>=10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ce87e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [ item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "\n",
    "        text = re.sub(r'\\s+([,.?\"()\\'])', r'\\1', text)\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d3c61e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9911d9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "eef1b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "95de66c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4fc3c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1085a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ebec1018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "dee6a413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "82ee9330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496,\n",
       " 11,\n",
       " 466,\n",
       " 345,\n",
       " 588,\n",
       " 8887,\n",
       " 30,\n",
       " 220,\n",
       " 50256,\n",
       " 554,\n",
       " 262,\n",
       " 4252,\n",
       " 18250,\n",
       " 8812,\n",
       " 2114,\n",
       " 1659,\n",
       " 617,\n",
       " 34680,\n",
       " 27271,\n",
       " 13]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integer = tokenizer.encode(text, allowed_special=\"all\")\n",
    "integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "23a85858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = tokenizer.decode(integer)\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df47f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fab1df99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/Users/vinithlankireddy/Projects/LLMs/GPT-2/f/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "enc_text[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "898e3bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5145"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0366cb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ---->  H\n",
      "I H ----> AD\n",
      "I HAD ---->  always\n",
      "I HAD always ---->  thought\n",
      "I HAD always thought ---->  Jack\n"
     ]
    }
   ],
   "source": [
    "context_size = 5\n",
    "\n",
    "enc_sample = enc_text[:20]\n",
    "\n",
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "21545d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt ,allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0,len(token_ids)- max_length , stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i+1 : i+max_length +1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4df2ffac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([15496,    11,   466]),\n",
       "  tensor([466, 345, 588]),\n",
       "  tensor([ 588, 8887,   30]),\n",
       "  tensor([   30,   220, 50256]),\n",
       "  tensor([50256,   554,   262]),\n",
       "  tensor([  262,  4252, 18250]),\n",
       "  tensor([18250,  8812,  2114]),\n",
       "  tensor([2114, 1659,  617]),\n",
       "  tensor([  617, 34680, 27271])],\n",
       " [tensor([ 11, 466, 345]),\n",
       "  tensor([ 345,  588, 8887]),\n",
       "  tensor([8887,   30,  220]),\n",
       "  tensor([  220, 50256,   554]),\n",
       "  tensor([ 554,  262, 4252]),\n",
       "  tensor([ 4252, 18250,  8812]),\n",
       "  tensor([8812, 2114, 1659]),\n",
       "  tensor([ 1659,   617, 34680]),\n",
       "  tensor([34680, 27271,    13])])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "dataset = GPTDatasetV1(text, tokenizer, 3,2)\n",
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9a05f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "46b91efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464, 1807],\n",
      "        [ 367, 2885, 1464, 1807, 3619]]), tensor([[ 367, 2885, 1464, 1807, 3619],\n",
      "        [2885, 1464, 1807, 3619,  402]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=2, max_length=5, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0480ec13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[2885, 1464, 1807, 3619,  402],\n",
      "        [1464, 1807, 3619,  402,  271]]), tensor([[ 1464,  1807,  3619,   402,   271],\n",
      "        [ 1807,  3619,   402,   271, 10899]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2129c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fa01147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e9c60451",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6033e517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3374, -0.1778, -0.1690],\n",
       "        [ 0.9178,  1.5810,  1.3010],\n",
       "        [ 1.2753, -0.2010, -0.1606],\n",
       "        [-0.4015,  0.9666, -1.1481],\n",
       "        [-1.1589,  0.3255, -0.6315],\n",
       "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "dfc98c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2753, -0.2010, -0.1606],\n",
       "        [-0.4015,  0.9666, -1.1481],\n",
       "        [-2.8400, -0.7849, -1.4096],\n",
       "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f25f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0224c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "246069cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim =256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "44d010ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets= next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "045d61d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "094a4f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "bf2dd2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "102e3ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  40,  367, 2885, 1464])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "93d3473e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b8097ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2956967., 16597455., 29439276., 30712224., 23737832.,  2581577.,\n",
      "        23769278., 12535636.])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "\n",
    "attntion_score2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attntion_score2[i] = torch.dot(x_i,query)\n",
    "\n",
    "print(attntion_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9aab991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0208, 0.1166, 0.2068, 0.2158, 0.1668, 0.0181, 0.1670, 0.0881])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attntion_weight2_tmp  = attntion_score2/attntion_score2.sum()\n",
    "\n",
    "print(attntion_weight2_tmp)\n",
    "attntion_weight2_tmp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5460a349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x)/torch.exp(x).sum(dim=0)\n",
    "\n",
    "attntion_weight2_naive = softmax_naive(attntion_score2)\n",
    "attntion_weight2_naive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "aab07888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def softmax_naive(x, dim=0):\n",
    "#     # x = x - x.max(dim=dim, keepdim=True).values\n",
    "#     exp_x = torch.exp(x)\n",
    "#     return exp_x / exp_x.sum(dim=dim, keepdim=True)\n",
    "\n",
    "# attntion_weight2_naive = softmax_naive(attntion_score2)\n",
    "# attntion_weight2_naive.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e0fc56af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attntion_weight2_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9976cd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2956967., 16597455., 29439276., 30712224., 23737832.,  2581577.,\n",
      "        23769278., 12535636.])\n"
     ]
    }
   ],
   "source": [
    "print(attntion_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2cc50f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attntion_score2, dim=0)\n",
    "attn_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f48d75a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15632.,   438.,  2016.,   257.])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1] \n",
    "\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i]*x_i\n",
    "\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "db99335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10602810,   2956967,  12248115,   6978434,   7386869,   2167885,\n",
      "           3789053,   2173569],\n",
      "        [  2956967,  16597455,  29439275,  30712225,  23737833,   2581577,\n",
      "          23769278,  12535636],\n",
      "        [ 12248115,  29439275, 172789970, 173633406,  26126256,  11545183,\n",
      "          27807641,  10279714],\n",
      "        [  6978434,  30712225, 173633406, 248681573,  20282744,   9945629,\n",
      "          19716576,   6538361],\n",
      "        [  7386869,  23737833,  26126256,  20282744,  38229585,   3396994,\n",
      "          36833363,  20132377],\n",
      "        [  2167885,   2581577,  11545183,   9945629,   3396994,    993378,\n",
      "           3057054,   1406905],\n",
      "        [  3789053,  23769278,  27807641,  19716576,  36833363,   3057054,\n",
      "          37133686,  20023897],\n",
      "        [  2173569,  12535636,  10279714,   6538361,  20132377,   1406905,\n",
      "          20023897,  10978278]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f1c70ed1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"softmax_lastdim_kernel_impl\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[232], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(attn_weights)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"softmax_lastdim_kernel_impl\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "be30f9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2139,  0.8846, -1.2506]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.7716, 0.2042, 0.0241]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(1,3)\n",
    "print(x)\n",
    "s = torch.softmax(x, dim=-1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "97daa3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self,d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query=nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key=nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value=nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self,x):\n",
    "        queries = x @ self.W_query\n",
    "        keys = x@ self.W_key \n",
    "        values = x@self.W_value \n",
    "\n",
    "        attention_score = queries @ keys.T\n",
    "        attention_weights = torch.softmax(\n",
    "            attention_score/keys.shape[-1]**0.5 , dim=-1\n",
    "        )\n",
    "        context_vec = attention_weights @ values\n",
    "        return context_vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "81da4748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self,d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query=nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in, d_out,bias = qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in, d_out,bias = qkv_bias)\n",
    "\n",
    "    def forward(self,x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attention_score = queries @ keys.T\n",
    "        attention_weights = torch.softmax(\n",
    "            attention_score/keys.shape[-1]**0.5 , dim=-1\n",
    "        )\n",
    "        context_vec = attention_weights @ values\n",
    "        return context_vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8cdd8b62",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: long long != float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[238], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m      2\u001b[0m sa_v1 \u001b[38;5;241m=\u001b[39m SelfAttention_v1(d_in, d_out)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msa_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[236], line 11\u001b[0m, in \u001b[0;36mSelfAttention_v1.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 11\u001b[0m     queries \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_query\u001b[49m\n\u001b[1;32m     12\u001b[0m     keys \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_key \n\u001b[1;32m     13\u001b[0m     values \u001b[38;5;241m=\u001b[39m x\u001b[38;5;129m@self\u001b[39m\u001b[38;5;241m.\u001b[39mW_value \n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: long long != float"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee2158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length,dropout qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Embedding(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Embedding(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Embedding(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length,context_length),1))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens , d_in = x.shape\n",
    "        query = x @ self.W_query\n",
    "        key = x @ self.W_key\n",
    "        value = x @ self.W_value\n",
    "\n",
    "        attn_socres = query @ key.transpose(1,2)\n",
    "        attn_scores.masked_fill_(\n",
    "            self.mask.bool()[: num_tokens, : num_tokens], -torch.inf\n",
    "        )\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores/key.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        context_vec = attn_weights @ value\n",
    "        return context_vec\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self,d_in, d_out, context_length,dropout,num_heads,qkv_bias = False):\n",
    "        super().__init__()\n",
    "        self.heads =nn.ModuleList(\n",
    "        [CausalAttention(d_in,d_out,context_length,dropout) \n",
    "         for _ in range(num_heads)]\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, din, dout, context_len,dropout,num_heads , qkv_bias = False):\n",
    "        super().__init__()\n",
    "        assert(dout%num_heads==0),\\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "        self.dout =dout\n",
    "        self.num_heads =num_heads\n",
    "        self.head_dim = dout//num_heads\n",
    "\n",
    "        self.W_query = nn.Linear(din,dout, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(din, dout, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(din,dout,bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(dout,dout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.mask = torch.triu(torch.ones(context_len,context_len), -1)\n",
    "        # self.register_buffer(\n",
    "        #     \"mask\",\n",
    "        #     torch.triu(torch.ones(context_len,context_len),\n",
    "        #     diagonal =1)                \n",
    "        #     )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        b, num_tokens, din = x.shape\n",
    "\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "        queries = self.W_query(x)\n",
    "\n",
    "        keys =keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b,num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens , self.num_heads, self.head_dim)\n",
    "\n",
    "        keys =keys.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "        queries = queries.transpose(1,2)\n",
    "\n",
    "        attn_score = queries @ keys.transpose(2,3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, : num_tokens]\n",
    "\n",
    "        attn_score.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_score/keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1,2)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b,num_tokens, self.dout)\n",
    "        context_vec  = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class batchNorm(nn.Module):\n",
    "    def __init__(self, num_features, eps =1e-5, momentum=0.1):\n",
    "        super().__init__()\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.eps =eps\n",
    "        self.momentum =momentum\n",
    "        self.running_mean = torch.zeros(num_features)\n",
    "        self.running_var = torch.ones(num_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            mean = torch.mean(x, dim=0)\n",
    "            var = torch.var(x, dim =0)\n",
    "\n",
    "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean\n",
    "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var\n",
    "  \n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            var =self.running_var\n",
    "        \n",
    "        x_hat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.gamma*x_hat + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef0ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layerNormCNN(nn.Model):\n",
    "    def __init__(self, num_channels, eps =1e-5):\n",
    "        self.num_channels = num_channels\n",
    "        self.eps = eps\n",
    "        self.beta = nn.Parameter(torch.zeros(num_channels))\n",
    "        self.gamma = nn.Parameter(torch.ones(num_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (C, H, W)\n",
    "        mean = x.mean(dim = (1,2,3), bias =False)\n",
    "        var= x.var(dim =(1,2,3), bias = False)\n",
    "\n",
    "        x_hat = (x - mean)/torch.sqrt(var + self.eps)\n",
    "        return self.gamma* x_hat + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layerNormTransform(nn.Model):\n",
    "    def __init__(self, normalized_shape, eps =1e-5):\n",
    "        self.eps = eps\n",
    "        self.beta = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.gamma = nn.Parameter(torch.ones(normalized_shape))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (B, seq_len, embed)\n",
    "        mean = x.mean(dim =-1, bias =False)\n",
    "        var= x.var(dim =-1, bias = False)\n",
    "\n",
    "        x_hat = (x - mean)/torch.sqrt(var + self.eps)\n",
    "        return self.gamma* x_hat + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNorm(nn.Model):\n",
    "    def __init__(self, num_channels, eps =1e-5):\n",
    "        self.eps = eps\n",
    "        self.beta = nn.Parameter(torch.zeros(num_channels))\n",
    "        self.gamma = nn.Parameter(torch.ones(num_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (B, seq_len, embed)\n",
    "        mean = x.mean(dim =-1, bias =False)\n",
    "        var= x.var(dim =-1, bias = False)\n",
    "\n",
    "        x_hat = (x - mean)/torch.sqrt(var + self.eps)\n",
    "        return self.gamma* x_hat + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNorm(nn.Module):\n",
    "    def __init__(self, num_channels, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(num_channels))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_channels))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (N, C, H, W)\n",
    "        mean = x.mean(dim=(2, 3), keepdim=True)\n",
    "        var = x.var(dim=(2, 3), keepdim=True, unbiased=False)\n",
    "        x_hat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.gamma.view(1, -1, 1, 1) * x_hat + self.beta.view(1, -1, 1, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
